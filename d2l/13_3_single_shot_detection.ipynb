{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOKHPO+iSHtzAjlu9VIXPss",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tongxi-Hu/deep-learning/blob/main/d2l/13_3_single_shot_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13-3 single shot detection"
      ],
      "metadata": {
        "id": "bz_drJkvbxq3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13-3-1 Multiscale Anchor Boxes"
      ],
      "metadata": {
        "id": "4P8TSicycEKL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2x-5ll8bbuG"
      },
      "outputs": [],
      "source": [
        "!pip3 install d2l==0.17.2\n",
        "%matplotlib inline\n",
        "import torch\n",
        "from d2l import torch as d2l\n",
        "\n",
        "img = d2l.plt.imread('../img/catdog.jpg')\n",
        "h, w = img.shape[:2]\n",
        "h, w"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_anchors(fmap_w,fmap_h,s):\n",
        "    d2l.set_figsize()\n",
        "    # Values on the first two dimensions do not affect the output\n",
        "    fmap=torch.zeros((1,10,fmap_h,fmap_w))\n",
        "    anchors=d2l.multibox_prior(fmap,sizes=s,ratios=[1,2,0.5])\n",
        "    bbox_scale=torch.tensor((w,h,w,h))\n",
        "    d2l.show_bboxes(d2l.plt.imgshow(img).axes,anchors[0].bbox_scale)"
      ],
      "metadata": {
        "id": "Ei711pDWcjvh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_anchors(fmap_w=4,fmap_h=4,s=[0.15])"
      ],
      "metadata": {
        "id": "68l1iC_UdF2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_anchors(fmap_w=2, fmap_h=2, s=[0.4])"
      ],
      "metadata": {
        "id": "yG4sdLtcdWjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13-3-2 Single Shot Multibox Detection"
      ],
      "metadata": {
        "id": "KV1gjv-Jdpqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from d2l import torch as d2l\n",
        "\n",
        "\n",
        "def cls_predictor(num_inputs, num_anchors, num_classes):\n",
        "    return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1),\n",
        "                     kernel_size=3, padding=1)"
      ],
      "metadata": {
        "id": "GSMZMsgKfRPC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bbox_predictor(num_inputs, num_anchors):\n",
        "    return nn.Conv2d(num_inputs, num_anchors * 4, kernel_size=3, padding=1)"
      ],
      "metadata": {
        "id": "ikJ_gfbRfWa2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x, block):\n",
        "    return block(x)\n",
        "\n",
        "Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))\n",
        "Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))\n",
        "Y1.shape, Y2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9NGzSLsfYbN",
        "outputId": "5fbab25f-bf2b-4c8a-aa49-5cc6ea1054e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 55, 20, 20]), torch.Size([2, 33, 10, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_pred(pred):\n",
        "    return torch.flatten(pred.permute(0, 2, 3, 1), start_dim=1)\n",
        "\n",
        "def concat_preds(preds):\n",
        "    return torch.cat([flatten_pred(p) for p in preds], dim=1)"
      ],
      "metadata": {
        "id": "8jZ6GAk9faUm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concat_preds([Y1, Y2]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5swuq6Xfcu_",
        "outputId": "fdad502a-cc88-45f4-84bf-f722c0c45ebd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 25300])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def down_sample_blk(in_channels, out_channels):\n",
        "    blk = []\n",
        "    for _ in range(2):\n",
        "        blk.append(nn.Conv2d(in_channels, out_channels,\n",
        "                             kernel_size=3, padding=1))\n",
        "        blk.append(nn.BatchNorm2d(out_channels))\n",
        "        blk.append(nn.ReLU())\n",
        "        in_channels = out_channels\n",
        "    blk.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*blk)"
      ],
      "metadata": {
        "id": "3ZAW0lQXfeiZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forward(torch.zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y3lvLBofgUr",
        "outputId": "d4e7ba2c-d37c-4a87-d64e-f4f23df69736"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def base_net():\n",
        "    blk = []\n",
        "    num_filters = [3, 16, 32, 64]\n",
        "    for i in range(len(num_filters) - 1):\n",
        "        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))\n",
        "    return nn.Sequential(*blk)\n",
        "\n",
        "forward(torch.zeros((2, 3, 256, 256)), base_net()).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dh_jENrfh7j",
        "outputId": "52215844-e8a6-4fa9-8e63-9e8c2b209018"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 64, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_blk(i):\n",
        "    if i == 0:\n",
        "        blk = base_net()\n",
        "    elif i == 1:\n",
        "        blk = down_sample_blk(64, 128)\n",
        "    elif i == 4:\n",
        "        blk = nn.AdaptiveMaxPool2d((1,1))\n",
        "    else:\n",
        "        blk = down_sample_blk(128, 128)\n",
        "    return blk"
      ],
      "metadata": {
        "id": "NCvokIdwfkAG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
        "    Y = blk(X)\n",
        "    anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio)\n",
        "    cls_preds = cls_predictor(Y)\n",
        "    bbox_preds = bbox_predictor(Y)\n",
        "    return (Y, anchors, cls_preds, bbox_preds)"
      ],
      "metadata": {
        "id": "b-9nuJi4flug"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],\n",
        "         [0.88, 0.961]]\n",
        "ratios = [[1, 2, 0.5]] * 5\n",
        "num_anchors = len(sizes[0]) + len(ratios[0]) - 1"
      ],
      "metadata": {
        "id": "283BHIjcfnVY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TinySSD(nn.Module):\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        super(TinySSD, self).__init__(**kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        idx_to_in_channels = [64, 128, 128, 128, 128]\n",
        "        for i in range(5):\n",
        "            # Equivalent to the assignment statement `self.blk_i = get_blk(i)`\n",
        "            setattr(self, f'blk_{i}', get_blk(i))\n",
        "            setattr(self, f'cls_{i}', cls_predictor(idx_to_in_channels[i],\n",
        "                                                    num_anchors, num_classes))\n",
        "            setattr(self, f'bbox_{i}', bbox_predictor(idx_to_in_channels[i],\n",
        "                                                      num_anchors))\n",
        "\n",
        "    def forward(self, X):\n",
        "        anchors, cls_preds, bbox_preds = [None] * 5, [None] * 5, [None] * 5\n",
        "        for i in range(5):\n",
        "            # Here `getattr(self, 'blk_%d' % i)` accesses `self.blk_i`\n",
        "            X, anchors[i], cls_preds[i], bbox_preds[i] = blk_forward(\n",
        "                X, getattr(self, f'blk_{i}'), sizes[i], ratios[i],\n",
        "                getattr(self, f'cls_{i}'), getattr(self, f'bbox_{i}'))\n",
        "        anchors = torch.cat(anchors, dim=1)\n",
        "        cls_preds = concat_preds(cls_preds)\n",
        "        cls_preds = cls_preds.reshape(\n",
        "            cls_preds.shape[0], -1, self.num_classes + 1)\n",
        "        bbox_preds = concat_preds(bbox_preds)\n",
        "        return anchors, cls_preds, bbox_preds"
      ],
      "metadata": {
        "id": "0R6RcTOefo-k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = TinySSD(num_classes=1)\n",
        "X = torch.zeros((32, 3, 256, 256))\n",
        "anchors, cls_preds, bbox_preds = net(X)\n",
        "\n",
        "print('output anchors:', anchors.shape)\n",
        "print('output class preds:', cls_preds.shape)\n",
        "print('output bbox preds:', bbox_preds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USxa4EMyfq4d",
        "outputId": "af5680fe-2efa-4bfa-d275-c870cc29b81d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output anchors: torch.Size([1, 5444, 4])\n",
            "output class preds: torch.Size([32, 5444, 2])\n",
            "output bbox preds: torch.Size([32, 21776])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_iter, _ = d2l.load_data_bananas(batch_size)\n",
        "device, net = d2l.try_gpu(), TinySSD(num_classes=1)\n",
        "trainer = torch.optim.SGD(net.parameters(), lr=0.2, weight_decay=5e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp-SiHNYftbe",
        "outputId": "d36e24e5-91d0-451a-aa3c-f3edb8676970"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ../data/banana-detection.zip from http://d2l-data.s3-accelerate.amazonaws.com/banana-detection.zip...\n",
            "read 1000 training examples\n",
            "read 100 validation examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cls_loss = nn.CrossEntropyLoss(reduction='none')\n",
        "bbox_loss = nn.L1Loss(reduction='none')\n",
        "\n",
        "def calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels, bbox_masks):\n",
        "    batch_size, num_classes = cls_preds.shape[0], cls_preds.shape[2]\n",
        "    cls = cls_loss(cls_preds.reshape(-1, num_classes),\n",
        "                   cls_labels.reshape(-1)).reshape(batch_size, -1).mean(dim=1)\n",
        "    bbox = bbox_loss(bbox_preds * bbox_masks,\n",
        "                     bbox_labels * bbox_masks).mean(dim=1)\n",
        "    return cls + bbox"
      ],
      "metadata": {
        "id": "ipB5ZN-gfxza"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_eval(cls_preds, cls_labels):\n",
        "    # Because the class prediction results are on the final dimension,\n",
        "    # `argmax` needs to specify this dimension\n",
        "    return float((cls_preds.argmax(dim=-1).type(\n",
        "        cls_labels.dtype) == cls_labels).sum())\n",
        "\n",
        "def bbox_eval(bbox_preds, bbox_labels, bbox_masks):\n",
        "    return float((torch.abs((bbox_labels - bbox_preds) * bbox_masks)).sum())"
      ],
      "metadata": {
        "id": "3WDxEn4Pf01c"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs, timer = 20, d2l.Timer()\n",
        "animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
        "                        legend=['class error', 'bbox mae'])\n",
        "net = net.to(device)\n",
        "for epoch in range(num_epochs):\n",
        "    # Sum of training accuracy, no. of examples in sum of training accuracy,\n",
        "    # Sum of absolute error, no. of examples in sum of absolute error\n",
        "    metric = d2l.Accumulator(4)\n",
        "    net.train()\n",
        "    for features, target in train_iter:\n",
        "        timer.start()\n",
        "        trainer.zero_grad()\n",
        "        X, Y = features.to(device), target.to(device)\n",
        "        # Generate multiscale anchor boxes and predict their classes and\n",
        "        # offsets\n",
        "        anchors, cls_preds, bbox_preds = net(X)\n",
        "        # Label the classes and offsets of these anchor boxes\n",
        "        bbox_labels, bbox_masks, cls_labels = d2l.multibox_target(anchors, Y)\n",
        "        # Calculate the loss function using the predicted and labeled values\n",
        "        # of the classes and offsets\n",
        "        l = calc_loss(cls_preds, cls_labels, bbox_preds, bbox_labels,\n",
        "                      bbox_masks)\n",
        "        l.mean().backward()\n",
        "        trainer.step()\n",
        "        metric.add(cls_eval(cls_preds, cls_labels), cls_labels.numel(),\n",
        "                   bbox_eval(bbox_preds, bbox_labels, bbox_masks),\n",
        "                   bbox_labels.numel())\n",
        "    cls_err, bbox_mae = 1 - metric[0] / metric[1], metric[2] / metric[3]\n",
        "    animator.add(epoch + 1, (cls_err, bbox_mae))\n",
        "print(f'class err {cls_err:.2e}, bbox mae {bbox_mae:.2e}')\n",
        "print(f'{len(train_iter.dataset) / timer.stop():.1f} examples/sec on '\n",
        "      f'{str(device)}')"
      ],
      "metadata": {
        "id": "nWF48zd3f26C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = torchvision.io.read_image('../img/banana.jpg').unsqueeze(0).float()\n",
        "img = X.squeeze(0).permute(1, 2, 0).long()"
      ],
      "metadata": {
        "id": "Ld3q3Upkf9jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X):\n",
        "    net.eval()\n",
        "    anchors, cls_preds, bbox_preds = net(X.to(device))\n",
        "    cls_probs = F.softmax(cls_preds, dim=2).permute(0, 2, 1)\n",
        "    output = d2l.multibox_detection(cls_probs, bbox_preds, anchors)\n",
        "    idx = [i for i, row in enumerate(output[0]) if row[0] != -1]\n",
        "    return output[0, idx]\n",
        "\n",
        "output = predict(X)"
      ],
      "metadata": {
        "id": "4AXgYYAugLQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display(img, output, threshold):\n",
        "    d2l.set_figsize((5, 5))\n",
        "    fig = d2l.plt.imshow(img)\n",
        "    for row in output:\n",
        "        score = float(row[1])\n",
        "        if score < threshold:\n",
        "            continue\n",
        "        h, w = img.shape[0:2]\n",
        "        bbox = [row[2:6] * torch.tensor((w, h, w, h), device=row.device)]\n",
        "        d2l.show_bboxes(fig.axes, bbox, '%.2f' % score, 'w')\n",
        "\n",
        "display(img, output.cpu(), threshold=0.9)"
      ],
      "metadata": {
        "id": "ND9QH5dUgNHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}