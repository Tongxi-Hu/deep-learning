{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4FgxUeJ6MbWdyMZvB9AC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tongxi-Hu/deep-learning/blob/main/pretrain-finetune%2Ccustom-dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1- pretrain-finetune"
      ],
      "metadata": {
        "id": "QKWmA-_jdpwl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VqJwbjbgcX-x"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Shows a small example of how to load a pretrain model (VGG16) from PyTorch,\n",
        "and modifies this to train on the CIFAR10 dataset. The same method generalizes\n",
        "well to other datasets, but the modifications to the network may need to be changed.\n",
        "\"\"\"\n",
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torch.nn.functional as F  # All functions that don't have any parameters\n",
        "from torch.utils.data import DataLoader  # Gives easier dataset managment and creates mini batches\n",
        "import torchvision.datasets as datasets  # Has standard datasets we can import in a nice way\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Hyperparameters\n",
        "num_classes = 10\n",
        "learning_rate = 1e-3\n",
        "batch_size = 1024\n",
        "num_epochs = 5"
      ],
      "metadata": {
        "id": "VegLINBXd7pW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Identity class that let's input pass without changes\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "metadata": {
        "id": "e53vWnk0eBBo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrain model & modify it\n",
        "model = torchvision.models.vgg16(pretrained=True)"
      ],
      "metadata": {
        "id": "of2WzVqieDoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to do finetuning then set requires_grad = False\n",
        "# Remove these two lines if you want to train entire model,\n",
        "# and only want to load the pretrain weights.\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.avgpool = Identity()\n",
        "model.classifier = nn.Sequential(nn.Linear(512, 100), nn.ReLU(), nn.Linear(100, num_classes))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "LkmIEUGieMBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "train_dataset = datasets.CIFAR10(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "7fQEd6uxeY7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    losses = []\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        losses.append(loss.item())\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_QrOYOgeiFf",
        "outputId": "4a589690-14c7-4e83-a991-45d1ca86ffe0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost at epoch 0 is 1.60119\n",
            "Cost at epoch 1 is 1.21212\n",
            "Cost at epoch 2 is 1.14597\n",
            "Cost at epoch 3 is 1.11156\n",
            "Cost at epoch 4 is 1.08989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "    if loader.dataset.train:\n",
        "        print(\"Checking accuracy on training data\")\n",
        "    else:\n",
        "        print(\"Checking accuracy on test data\")\n",
        "\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "        print(\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
        "        )\n",
        "\n",
        "    model.train()\n",
        "\n",
        "\n",
        "check_accuracy(train_loader, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAIgxZF5en9i",
        "outputId": "dd045529-c406-4ab8-9fb4-44809654b296"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on training data\n",
            "Got 31261 / 50000 with accuracy 62.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2-custom-dataset-image"
      ],
      "metadata": {
        "id": "IqeJQl40hHPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Example of how to create custom dataset in Pytorch. In this case\n",
        "we have images of cats and dogs in a separate folder and a csv\n",
        "file containing the name to the jpg file as well as the target\n",
        "label (0 for cat, 1 for dog).\n",
        "\"\"\"\n",
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
        "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
        "import torchvision\n",
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "from torch.utils.data import (Dataset,DataLoader,)  # Gives easier dataset managment and creates mini batches\n"
      ],
      "metadata": {
        "id": "-_vhhwWNhOLa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CatsAndDogsDataset(Dataset):\n",
        "    def __init__(self,csv_file,root_dir,transform=None) -> None:\n",
        "        super().__init__()\n",
        "        self.annotations=pd.read_csv(csv_file)\n",
        "        self.root_dir=root_dir\n",
        "        self.transform=transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "    \n",
        "    def __getitem__(self,index):\n",
        "        img_path=os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
        "        image=io.imread(img_path)\n",
        "        y_label=torch.tensor(int(self.annotations.iloc[index,1]))\n",
        "\n",
        "        if self.transform:\n",
        "            image=self.transform(image)\n",
        "        return (image,y_label)"
      ],
      "metadata": {
        "id": "fZmNG0PHhUZX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "in_channel = 3\n",
        "num_classes = 2\n",
        "learning_rate = 1e-3\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "# Load Data\n",
        "dataset = CatsAndDogsDataset(csv_file=\"cats_dogs.csv\",root_dir=\"cats_dogs_resized\",transform=transforms.ToTensor())\n",
        "\n",
        "# Dataset is actually a lot larger ~25k images, just took out 10 pictures\n",
        "# to upload to Github. It's enough to understand the structure and scale\n",
        "# if you got more images.\n",
        "train_set, test_set = torch.utils.data.random_split(dataset, [5, 5])\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "EI4l9qJaibJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "model = torchvision.models.googlenet(pretrained=True)\n",
        "model.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "C8ALNxGcjlx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-custom-dataset-text"
      ],
      "metadata": {
        "id": "atR5LtjjjnPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # when loading file paths\n",
        "import pandas as pd  # for lookup in annotation file\n",
        "import spacy  # for tokenizer\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence  # pad batch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image  # Load img\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# We want to convert text -> numerical values\n",
        "# 1. We need a Vocabulary mapping each word to a index\n",
        "# 2. We need to setup a Pytorch dataset to load the data\n",
        "# 3. Setup padding of every batch (all examples should be\n",
        "#    of same seq_len and setup dataloader)\n",
        "# Note that loading the image is very easy compared to the text!\n",
        "\n",
        "# Download with: python -m spacy download en\n",
        "spacy_eng = spacy.load(\"en\")\n",
        "\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold):\n",
        "        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer_eng(text):\n",
        "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
        "\n",
        "    def build_vocabulary(self, sentence_list):\n",
        "        frequencies = {}\n",
        "        idx = 4\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "            for word in self.tokenizer_eng(sentence):\n",
        "                if word not in frequencies:\n",
        "                    frequencies[word] = 1\n",
        "\n",
        "                else:\n",
        "                    frequencies[word] += 1\n",
        "\n",
        "                if frequencies[word] == self.freq_threshold:\n",
        "                    self.stoi[word] = idx\n",
        "                    self.itos[idx] = word\n",
        "                    idx += 1\n",
        "\n",
        "    def numericalize(self, text):\n",
        "        tokenized_text = self.tokenizer_eng(text)\n",
        "\n",
        "        return [\n",
        "            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n",
        "            for token in tokenized_text\n",
        "        ]\n",
        "\n",
        "\n",
        "class FlickrDataset(Dataset):\n",
        "    def __init__(self, root_dir, captions_file, transform=None, freq_threshold=5):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = pd.read_csv(captions_file)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Get img, caption columns\n",
        "        self.imgs = self.df[\"image\"]\n",
        "        self.captions = self.df[\"caption\"]\n",
        "\n",
        "        # Initialize vocabulary and build vocab\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        self.vocab.build_vocabulary(self.captions.tolist())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        caption = self.captions[index]\n",
        "        img_id = self.imgs[index]\n",
        "        img = Image.open(os.path.join(self.root_dir, img_id)).convert(\"RGB\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        numericalized_caption = [self.vocab.stoi[\"<SOS>\"]]\n",
        "        numericalized_caption += self.vocab.numericalize(caption)\n",
        "        numericalized_caption.append(self.vocab.stoi[\"<EOS>\"])\n",
        "\n",
        "        return img, torch.tensor(numericalized_caption)\n",
        "\n",
        "\n",
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        imgs = [item[0].unsqueeze(0) for item in batch]\n",
        "        imgs = torch.cat(imgs, dim=0)\n",
        "        targets = [item[1] for item in batch]\n",
        "        targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx)\n",
        "\n",
        "        return imgs, targets\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    root_folder,\n",
        "    annotation_file,\n",
        "    transform,\n",
        "    batch_size=32,\n",
        "    num_workers=8,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "):\n",
        "    dataset = FlickrDataset(root_folder, annotation_file, transform=transform)\n",
        "\n",
        "    pad_idx = dataset.vocab.stoi[\"<PAD>\"]\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=shuffle,\n",
        "        pin_memory=pin_memory,\n",
        "        collate_fn=MyCollate(pad_idx=pad_idx),\n",
        "    )\n",
        "\n",
        "    return loader, dataset\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.Resize((224, 224)), transforms.ToTensor(),]\n",
        "    )\n",
        "\n",
        "    loader, dataset = get_loader(\n",
        "        \"flickr8k/images/\", \"flickr8k/captions.txt\", transform=transform\n",
        "    )\n",
        "\n",
        "    for idx, (imgs, captions) in enumerate(loader):\n",
        "        print(imgs.shape)\n",
        "        print(captions.shape)"
      ],
      "metadata": {
        "id": "f7T5IesgkR7p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}